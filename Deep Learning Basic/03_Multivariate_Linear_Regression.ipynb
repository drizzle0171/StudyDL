{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 Multivariate Linear Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Multivariate Linear Regression"
      ],
      "metadata": {
        "id": "Pnql1coDFMrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "yqNzoE-vGJDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "cPeY_wi0FRVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2Kem9RKFIiR"
      },
      "outputs": [],
      "source": [
        "w = torch.zeros((3,1), requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([w, b], lr = 0.0001)"
      ],
      "metadata": {
        "id": "SvGPWFY-GG4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 50\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  y_hat = x_train.matmul(w)+b\n",
        "  cost = torch.mean((y_hat-y_train)**2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, y_hat.squeeze().detach(),\n",
        "      cost.item()\n",
        "  ))\n",
        "  # y_hat.squeeze().detach() = w.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-x3wdHeGTv1",
        "outputId": "a7f7276a-3c5c-4a0a-96ee-bff4c409ecd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/50 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch    1/50 hypothesis: tensor([672.5779, 808.3967, 796.5228, 867.3937, 616.6049]) Cost: 343148.906250\n",
            "Epoch    2/50 hypothesis: tensor([-1615.1255, -1941.2439, -1912.7493, -2082.9355, -1480.6765]) Cost: 3969974.500000\n",
            "Epoch    3/50 hypothesis: tensor([6166.1748, 7411.3062, 7302.4741, 7952.2119, 5652.9658]) Cost: 45929800.000000\n",
            "Epoch    4/50 hypothesis: tensor([-20300.9023, -24400.1367, -24041.8906, -26181.0117, -18611.1523]) Cost: 531375520.000000\n",
            "Epoch    5/50 hypothesis: tensor([69723.3281, 83802.2734, 82571.7891, 89918.6094, 63920.0352]) Cost: 6147641856.000000\n",
            "Epoch    6/50 hypothesis: tensor([-236482.1250, -284233.8438, -280060.5000, -304978.8438, -216798.7969]) Cost: 71123902464.000000\n",
            "Epoch    7/50 hypothesis: tensor([ 805035.0625,  967592.1875,  953385.0625, 1038212.4375,  738029.1875]) Cost: 822853828608.000000\n",
            "Epoch    8/50 hypothesis: tensor([-2737547.7500, -3290328.0000, -3242016.2500, -3530474.7500,\n",
            "        -2509691.7500]) Cost: 9519843246080.000000\n",
            "Epoch    9/50 hypothesis: tensor([ 9312077., 11192422., 11028085., 12009308.,  8536999.]) Cost: 110137901580288.000000\n",
            "Epoch   10/50 hypothesis: tensor([-31673122., -38068728., -37509768., -40847196., -29036854.]) Cost: 1274218280910848.000000\n",
            "Epoch   11/50 hypothesis: tensor([1.0773e+08, 1.2949e+08, 1.2759e+08, 1.3894e+08, 9.8766e+07]) Cost: 14741811671072768.000000\n",
            "Epoch   12/50 hypothesis: tensor([-3.6644e+08, -4.4043e+08, -4.3396e+08, -4.7258e+08, -3.3594e+08]) Cost: 170552429769654272.000000\n",
            "Epoch   13/50 hypothesis: tensor([1.2464e+09, 1.4981e+09, 1.4761e+09, 1.6074e+09, 1.1426e+09]) Cost: 1973172297212624896.000000\n",
            "Epoch   14/50 hypothesis: tensor([-4.2394e+09, -5.0955e+09, -5.0207e+09, -5.4674e+09, -3.8866e+09]) Cost: 22828218745559711744.000000\n",
            "Epoch   15/50 hypothesis: tensor([1.4420e+10, 1.7332e+10, 1.7077e+10, 1.8597e+10, 1.3220e+10]) Cost: 264106510496166838272.000000\n",
            "Epoch   16/50 hypothesis: tensor([-4.9047e+10, -5.8951e+10, -5.8085e+10, -6.3254e+10, -4.4965e+10]) Cost: 3055527121359552380928.000000\n",
            "Epoch   17/50 hypothesis: tensor([1.6683e+11, 2.0051e+11, 1.9757e+11, 2.1515e+11, 1.5294e+11]) Cost: 35350313972501906980864.000000\n",
            "Epoch   18/50 hypothesis: tensor([-5.6744e+11, -6.8202e+11, -6.7201e+11, -7.3180e+11, -5.2021e+11]) Cost: 408978367344978155274240.000000\n",
            "Epoch   19/50 hypothesis: tensor([1.9301e+12, 2.3198e+12, 2.2857e+12, 2.4891e+12, 1.7694e+12]) Cost: 4731592737210261506621440.000000\n",
            "Epoch   20/50 hypothesis: tensor([-6.5649e+12, -7.8905e+12, -7.7747e+12, -8.4664e+12, -6.0185e+12]) Cost: 54741215712509103005761536.000000\n",
            "Epoch   21/50 hypothesis: tensor([2.2330e+13, 2.6839e+13, 2.6444e+13, 2.8797e+13, 2.0471e+13]) Cost: 633317380674387362829041664.000000\n",
            "Epoch   22/50 hypothesis: tensor([-7.5951e+13, -9.1288e+13, -8.9947e+13, -9.7951e+13, -6.9630e+13]) Cost: 7327038481936088879996076032.000000\n",
            "Epoch   23/50 hypothesis: tensor([2.5834e+14, 3.1050e+14, 3.0594e+14, 3.3317e+14, 2.3684e+14]) Cost: 84768688435024114579803209728.000000\n",
            "Epoch   24/50 hypothesis: tensor([-8.7870e+14, -1.0561e+15, -1.0406e+15, -1.1332e+15, -8.0557e+14]) Cost: 980714323678608944309894905856.000000\n",
            "Epoch   25/50 hypothesis: tensor([2.9888e+15, 3.5923e+15, 3.5396e+15, 3.8545e+15, 2.7400e+15]) Cost: 11346177434010324549278512447488.000000\n",
            "Epoch   26/50 hypothesis: tensor([-1.0166e+16, -1.2219e+16, -1.2039e+16, -1.3111e+16, -9.3198e+15]) Cost: 131267312546012071371010868248576.000000\n",
            "Epoch   27/50 hypothesis: tensor([3.4578e+16, 4.1560e+16, 4.0950e+16, 4.4594e+16, 3.1700e+16]) Cost: 1518670487359214351943617147305984.000000\n",
            "Epoch   28/50 hypothesis: tensor([-1.1761e+17, -1.4136e+17, -1.3929e+17, -1.5168e+17, -1.0782e+17]) Cost: 17569951755933237991334130804064256.000000\n",
            "Epoch   29/50 hypothesis: tensor([4.0005e+17, 4.8083e+17, 4.7377e+17, 5.1592e+17, 3.6675e+17]) Cost: 203272012453291097672057613583384576.000000\n",
            "Epoch   30/50 hypothesis: tensor([-1.3607e+18, -1.6355e+18, -1.6115e+18, -1.7548e+18, -1.2474e+18]) Cost: 2351714653016355651093697491560824832.000000\n",
            "Epoch   31/50 hypothesis: tensor([4.6283e+18, 5.5628e+18, 5.4811e+18, 5.9688e+18, 4.2430e+18]) Cost: 27207688780047706359134663626647928832.000000\n",
            "Epoch   32/50 hypothesis: tensor([-1.5742e+19, -1.8921e+19, -1.8643e+19, -2.0302e+19, -1.4432e+19]) Cost: inf\n",
            "Epoch   33/50 hypothesis: tensor([5.3546e+19, 6.4358e+19, 6.3413e+19, 6.9055e+19, 4.9089e+19]) Cost: inf\n",
            "Epoch   34/50 hypothesis: tensor([-1.8213e+20, -2.1890e+20, -2.1569e+20, -2.3488e+20, -1.6697e+20]) Cost: inf\n",
            "Epoch   35/50 hypothesis: tensor([6.1949e+20, 7.4457e+20, 7.3364e+20, 7.9892e+20, 5.6792e+20]) Cost: inf\n",
            "Epoch   36/50 hypothesis: tensor([-2.1071e+21, -2.5326e+21, -2.4954e+21, -2.7174e+21, -1.9317e+21]) Cost: inf\n",
            "Epoch   37/50 hypothesis: tensor([7.1670e+21, 8.6142e+21, 8.4877e+21, 9.2429e+21, 6.5705e+21]) Cost: inf\n",
            "Epoch   38/50 hypothesis: tensor([-2.4378e+22, -2.9300e+22, -2.8870e+22, -3.1439e+22, -2.2349e+22]) Cost: inf\n",
            "Epoch   39/50 hypothesis: tensor([8.2917e+22, 9.9660e+22, 9.8197e+22, 1.0693e+23, 7.6016e+22]) Cost: inf\n",
            "Epoch   40/50 hypothesis: tensor([-2.8203e+23, -3.3898e+23, -3.3400e+23, -3.6372e+23, -2.5856e+23]) Cost: inf\n",
            "Epoch   41/50 hypothesis: tensor([9.5929e+23, 1.1530e+24, 1.1361e+24, 1.2372e+24, 8.7945e+23]) Cost: inf\n",
            "Epoch   42/50 hypothesis: tensor([-3.2629e+24, -3.9218e+24, -3.8642e+24, -4.2080e+24, -2.9913e+24]) Cost: inf\n",
            "Epoch   43/50 hypothesis: tensor([1.1098e+25, 1.3339e+25, 1.3144e+25, 1.4313e+25, 1.0175e+25]) Cost: inf\n",
            "Epoch   44/50 hypothesis: tensor([-3.7750e+25, -4.5372e+25, -4.4706e+25, -4.8684e+25, -3.4608e+25]) Cost: inf\n",
            "Epoch   45/50 hypothesis: tensor([1.2840e+26, 1.5433e+26, 1.5206e+26, 1.6559e+26, 1.1771e+26]) Cost: inf\n",
            "Epoch   46/50 hypothesis: tensor([-4.3674e+26, -5.2492e+26, -5.1722e+26, -5.6324e+26, -4.0039e+26]) Cost: inf\n",
            "Epoch   47/50 hypothesis: tensor([1.4855e+27, 1.7855e+27, 1.7592e+27, 1.9158e+27, 1.3619e+27]) Cost: inf\n",
            "Epoch   48/50 hypothesis: tensor([-5.0527e+27, -6.0730e+27, -5.9838e+27, -6.5163e+27, -4.6322e+27]) Cost: inf\n",
            "Epoch   49/50 hypothesis: tensor([1.7186e+28, 2.0657e+28, 2.0353e+28, 2.2164e+28, 1.5756e+28]) Cost: inf\n",
            "Epoch   50/50 hypothesis: tensor([-5.8457e+28, -7.0260e+28, -6.9229e+28, -7.5388e+28, -5.3591e+28]) Cost: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Module 사용하기\n",
        "\n",
        "w = torch.zeros((3,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "y_hat = x_train.matmul(w)+b"
      ],
      "metadata": {
        "id": "I_6G7E50Hnku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3,1)\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = MultivariateLinearRegressionModel()"
      ],
      "metadata": {
        "id": "MlxCFLqEH3VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([w, b], lr = 1e-5)"
      ],
      "metadata": {
        "id": "j3mmBtmyI0oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  y_hat = model(x_train)\n",
        "  cost = F.mse_loss(y_hat, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, y_hat.squeeze().detach(),\n",
        "      cost.item()\n",
        "  ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhPF-_H6If0E",
        "outputId": "7c4edff7-afb4-480b-d049-f5067db629ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    1/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    2/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    3/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    4/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    5/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    6/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    7/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    8/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch    9/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   10/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   11/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   12/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   13/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   14/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   15/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   16/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   17/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   18/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   19/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n",
            "Epoch   20/20 hypothesis: tensor([15.3976, 23.6164, 20.6093, 22.2009, 19.5873]) Cost: 23060.255859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "nuvY5Z3ZX2SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_train = ([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "    self.y_train = ([[152], [185], [180], [196], [142]])\n",
        "  \n",
        "  def __len__(self): # 데이터의 총 개수\n",
        "    return len(self.x_data)\n",
        "  \n",
        "  def __getiem__(self, idx): # 어떠한 idx를 받았을 때, 그에 상응하는 입력과 출력 데이터 반환\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "\n",
        "    return x, y\n",
        "\n",
        "dataset = CustomDataset()"
      ],
      "metadata": {
        "id": "-K4dGrfuX_ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Q86a3n9aYRDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "nb_epochs = 50\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader), cost.itme()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "EyseTu1YZRME",
        "outputId": "ae81a67c-28b7-472e-92e2-c40ed9e6576f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-712eb7ac0ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     99\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# dataset size might change at runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4c41d4a98c04>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 데이터의 총 개수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getiem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 어떠한 idx를 받았을 때, 그에 상응하는 입력과 출력 데이터 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attribute_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}